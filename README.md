Reference:

https://blog.llamaindex.ai/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab


Installation of ollama (from [ollama download](https://ollama.ai/download))
`curl https://ollama.ai/install.sh | sh`

Getting started

`ollama run mixtral` 

Running/stopping the ollama service on local

`sudo systemctl status ollama`

`sudo systemctl stop/start ollama`